{
  "models": [
    {
      "name": "Qwen2.5-Coder-14B-Instruct",
      "repo_id": "Qwen/Qwen2.5-Coder-14B-Instruct-GGUF",
      "filename": "qwen2.5-coder-14b-instruct-q8_0.gguf",
      "description": "State-of-the-art coding model (14B) in high precision Q8. Safe size (~16GB).",
      "context_window": 32768
    },
    {
      "name": "GLM-4-9B-Chat",
      "repo_id": "second-state/glm-4-9b-chat-GGUF",
      "filename": "glm-4-9b-chat-Q8_0.gguf",
      "description": "Strong generalist model (9B) with excellent reasoning. Safe size (~10GB).",
      "context_window": 32768
    },
    {
      "name": "DeepSeek-R1-Distill-Qwen-14B",
      "repo_id": "unsloth/DeepSeek-R1-Distill-Qwen-14B-GGUF",
      "filename": "DeepSeek-R1-Distill-Qwen-14B-Q8_0.gguf",
      "description": "Powerful reasoning model (14B Qwen-based). Better than Llama-8B. Safe size (15.7GB).",
      "context_window": 131072
    },
    {
      "name": "Ministral-3-14B-Reasoning-2512-Q8_0.gguf",
      "repo_id": "mistralai/Ministral-3-14B-Reasoning-2512-GGUF",
      "filename": "Ministral-3-14B-Reasoning-2512-Q8_0.gguf",
      "description": "Ministral 3 14B Reasoning (Q8_0)."
    },
    {
      "name": "Step3-VL-10B-F16.gguf",
      "repo_id": "seanbailey518/Step3-VL-10B-GGUF",
      "filename": "Step3-VL-10B-F16.gguf",
      "description": "Step3 VL 10B (F16)."
    },
    {
      "name": "Phi-4-reasoning-plus-Q8_0.gguf",
      "repo_id": "lmstudio-community/Phi-4-reasoning-plus-GGUF",
      "filename": "Phi-4-reasoning-plus-Q8_0.gguf",
      "description": "Phi-4 Reasoning Plus (Q8_0)."
    },

    {
      "name": "GLM-4.7-Flash-Q4_K_M-latest.gguf",
      "repo_id": "zai-org/GLM-4.7-Flash-GGUF",
      "filename": "glm-4.7-flash-q4_k_m.gguf",
      "description": "User confirmed GLM-4.7 Flash model."
    },
    {
      "name": "gemma-3-27b-it.Q4_K_M.gguf",
      "repo_id": "google/gemma-3-27b-it-GGUF",
      "filename": "gemma-3-27b-it-q4_k_m.gguf",
      "description": "Gemma 3 27B Instruct model."
    },
    {
      "name": "DeepSeek-R1-Distill-Qwen-32B-Uncensored.Q4_K_M.gguf",
      "repo_id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B-GGUF",
      "filename": "deepseek-r1-distill-qwen-32b-q4_k_m.gguf",
      "description": "DeepSeek R1 Distill Qwen 32B (Uncensored)."
    },
    {
      "name": "phi4-14b.gguf",
      "repo_id": "microsoft/phi-4-GGUF",
      "filename": "phi-4-q4_k_m.gguf",
      "description": "Phi-4 14B model."
    },
    {
      "name": "mistral-7b.gguf",
      "repo_id": "mistralai/Mistral-7B-Instruct-v0.3-GGUF",
      "filename": "mistral-7b-instruct-v0.3-q4_k_m.gguf",
      "description": "Mistral 7B Instruct v0.3."
    },
    {
      "name": "llama3.1-8b.gguf",
      "repo_id": "meta-llama/Meta-Llama-3.1-8B-Instruct-GGUF",
      "filename": "meta-llama-3.1-8b-instruct-q4_k_m.gguf",
      "description": "Llama 3.1 8B Instruct."
    },
    {
      "name": "llama3.2-3b.gguf",
      "repo_id": "meta-llama/Llama-3.2-3B-Instruct-GGUF",
      "filename": "llama-3.2-3b-instruct-q4_k_m.gguf",
      "description": "Llama 3.2 3B Instruct."
    },
    {
      "name": "gemma2-9b.gguf",
      "repo_id": "google/gemma-2-9b-it-GGUF",
      "filename": "gemma-2-9b-it-q4_k_m.gguf",
      "description": "Gemma 2 9B Instruct."
    },
    {
      "name": "gemma2-27b.gguf",
      "repo_id": "google/gemma-2-27b-it-GGUF",
      "filename": "gemma-2-27b-it-q4_k_m.gguf",
      "description": "Gemma 2 27B Instruct."
    },
    {
      "name": "Qwen3-30B-A3B-Thinking-2507-Q4_K_M-latest.gguf",
      "repo_id": "unsloth/Qwen3-30B-A3B-Thinking-2507-GGUF",
      "filename": "Qwen3-30B-A3B-Thinking-2507-Q4_K_M.gguf",
      "description": "Qwen3 30B A3B Thinking 2507 - Preview model."
    },
    {
      "name": "phi-4-Q8_0.gguf",
      "repo_id": "unsloth/phi-4-GGUF",
      "filename": "phi-4-Q8_0.gguf",
      "description": "Phi-4 Q8_0 - Unsloth quantization."
    },
    {
      "name": "gpt-oss-20b-uncensored.Q4_K_M.gguf",
      "repo_id": "mradermacher/gpt-oss-20b-uncensored-GGUF",
      "filename": "gpt-oss-20b-uncensored.Q4_K_M.gguf",
      "description": "GPT-OSS 20B Uncensored - Q4_K_M."
    },
    {
      "name": "gpt-oss-20b-uncensored.Q8_0.gguf",
      "repo_id": "mradermacher/gpt-oss-20b-uncensored-GGUF",
      "filename": "gpt-oss-20b-uncensored.Q8_0.gguf",
      "description": "GPT-OSS 20B Uncensored - Q8_0."
    },
    {
      "name": "Nemotron-3-Nano-30B-A3B-Q4_K_M.gguf",
      "repo_id": "unsloth/Nemotron-3-Nano-30B-A3B-GGUF",
      "filename": "Nemotron-3-Nano-30B-A3B-Q4_K_M.gguf",
      "description": "Nemotron-3 Nano 30B A3B - Unsloth optimized."
    },
    {
      "name": "Qwen3-VL-30B-A3B-Thinking-Q4_K_M.gguf",
      "repo_id": "unsloth/Qwen3-VL-30B-A3B-Thinking-GGUF",
      "filename": "Qwen3-VL-30B-A3B-Thinking-Q4_K_M.gguf",
      "description": "Qwen3-VL 30B A3B Thinking - Q4_K_M."
    },

    {
      "name": "nomic-embed-text-v2-moe.f16.gguf",
      "repo_id": "nomic-ai/nomic-embed-text-v2-moe-GGUF",
      "filename": "nomic-embed-text-v2-moe.f16.gguf",
      "description": "Nomic Embed Text v2 MoE (F16) - Embedding Model."
    }
  ]
}